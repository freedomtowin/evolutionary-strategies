{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: -0.5555555555555555\n",
       "     jac: array([-0.66666665,  1.        ])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 8\n",
       "     nit: 2\n",
       "    njev: 2\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([-0.33333333, -0.66666667])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\"\"\"\n",
    "The following is a simple constrained minimization problem.\n",
    "\n",
    "The scipy.optimize.minimize function can take equality and inequality constraints.\n",
    "\n",
    "The equality and inequality constraints are represented by f(x)=0 and f(x)>0, respectively.\n",
    "\n",
    "obj: x**2+y\n",
    "\n",
    "s.t.\n",
    "\n",
    "2*x - y = 0\n",
    "\n",
    "x + y + 1 > 0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def objective(X):\n",
    "    x, y = X\n",
    "    \n",
    "    return x**2 + y\n",
    "\n",
    "def eq(X):\n",
    "    x, y = X\n",
    "    return 2 * x - y\n",
    "\n",
    "def ineq(X):\n",
    "    x, y = X\n",
    "    return x + y + 1\n",
    "\n",
    "sol = minimize(objective, [1, -0.5], constraints=({'type': 'eq', 'fun': eq},\n",
    "                                                  {'type': 'ineq', 'fun': ineq}))\n",
    "\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scipy uses SLSQP as the default solver for constrained optimization. \n",
    "\n",
    "Genetic optimization utilizes chaotic mutations which require a smooth loss function.\n",
    "\n",
    "To accomplish this an L2 penalty (P1 & P2) is applied when the constraints are not met.\n",
    "\n",
    "P1 * equality_constraint(x)**2 + P2 * min(0,inequality_constraint(x))**2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def smooth_objective(X):\n",
    "    x, y = X\n",
    "    \n",
    "    return (x**2 + y) + 10*eq(X)**2 + 10*min(0,ineq(X))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "The search bound for the 1st generation can be defined explictly.\n",
    "\"\"\"\n",
    "\n",
    "pop_size = 10001\n",
    "bounds = ((-5,5),(-5,5))\n",
    "\n",
    "#actual solution\n",
    "SOL = sol.x\n",
    "\n",
    "\n",
    "X = [np.random.uniform(l,u,size=(1,101)) for l,u in bounds]\n",
    "X = np.vstack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5682061225212588\n"
     ]
    }
   ],
   "source": [
    "print(np.min(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The best parameters are sorted from smallest to largest.\n",
    "\n",
    "Should half of the population be removed?\n",
    "\n",
    "Then the population is split into 1...n (best) and n+1...m (other)\n",
    "\"\"\"\n",
    "\n",
    "L = np.array([smooth_objective(X[:,i]) for i in range(X.shape[1])])\n",
    "\n",
    "shift = np.argsort(L)\n",
    "\n",
    "L = L[shift]\n",
    "X = X[:,shift]\n",
    "\n",
    "X = X[:,:X.shape[1] - X.shape[1]%2]\n",
    "\n",
    "X_N = X[:,:X.shape[1]//2] \n",
    "X_M = X[:,X.shape[1]//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 minimum loss -0.5682065217328194\n",
      "iteration 1 minimum loss -0.5682065217362197\n",
      "iteration 2 minimum loss -0.5682065217380334\n",
      "iteration 3 minimum loss -0.5682065217382758\n",
      "iteration 4 minimum loss -0.5682065217384538\n",
      "iteration 5 minimum loss -0.5682065217385865\n",
      "iteration 6 minimum loss -0.5682065217386401\n",
      "iteration 7 minimum loss -0.5682065217386854\n",
      "iteration 8 minimum loss -0.5682065217387151\n",
      "iteration 9 minimum loss -0.5682065217387383\n"
     ]
    }
   ],
   "source": [
    "DATA = []\n",
    "for _ in range(10):\n",
    "    Y_N = np.zeros((X.shape[0],X.shape[1]//2))\n",
    "    Y_M = np.zeros((X.shape[0],X.shape[1]//2))\n",
    "    Y_K = np.zeros((X.shape[0],X.shape[1]//2))\n",
    "    Y_L = np.zeros((X.shape[0],X.shape[1]//2))\n",
    "    MUT = np.zeros((X.shape[0],X.shape[1]//2))\n",
    "\n",
    "    BEST = X[:,0] \n",
    "    \n",
    "    DATA.append(X[:,0:1])\n",
    "\n",
    "    for i in range(X.shape[1]//2):\n",
    "        \n",
    "        \"\"\"\n",
    "        The distribution based crossovers are created with directional components\n",
    "        (1) - an average of the top N samples, TOP_N_AVG\n",
    "        (2) - the current best sample, BEST\n",
    "        (3) - an average of (1),(2), and the ith sample of the top N samples, X_N[:,i]\n",
    "        \n",
    "        (2) defined the center of a normal distribution crossover operation.\n",
    "        The variation around this point is defined by the uniform variation between (1) and (2)\n",
    "        \n",
    "        (3) defined the center of a normal distribution crossover operation.\n",
    "        The variation around this point is defined by the uniform variation between\n",
    "        X_N[:,i] and X_M[:,i].\n",
    "        \n",
    "        (2) defined the initial point of a uniform distribution crossover.\n",
    "        The point is shifted in a randomly in the direction between X_N[:,i]-X_M[:,i]\n",
    "        \n",
    "        (3) defined the initial point of a uniform distribution crossover.\n",
    "        The point is shifted in a randomly in the direction between (2)-(3)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        TOP_N_AVG = np.mean(X_N,axis=1)\n",
    "\n",
    "        DIRECTION_AVG = 1./3. * (TOP_N_AVG+BEST+X_N[:,i])\n",
    "\n",
    "        DIRECTION_DEV = ((X_N[:,i] - X_M[:,i])/12)**2 + 1e-9\n",
    "\n",
    "        BEST_DEV = ((BEST-TOP_N_AVG)/12)**2 + 1e-9\n",
    "\n",
    "        Y_N[:,i] = [np.random.normal(DIRECTION_AVG[j],DIRECTION_DEV[j]) for j in range(X.shape[0])]\n",
    "\n",
    "        Y_M[:,i] = [np.random.normal(BEST[j],BEST_DEV[j]) for j in range(X.shape[0])]\n",
    "        \n",
    "        Y_K[:,i] = BEST + np.random.uniform(0,1)*(X_N[:,i]-X_M[:,i])\n",
    "        \n",
    "        Y_L[:,i] = DIRECTION_AVG + np.random.uniform(0,1)*(BEST-DIRECTION_AVG)\n",
    "\n",
    "        \"\"\"\n",
    "        Different mutation operators are used depending on the iteration\n",
    "        1 - Cauchy mutation operator\n",
    "        2 - normal mutation operator\n",
    "        3 - levy flight mutation operator https://arxiv.org/pdf/1303.6342.pdf\n",
    "        \"\"\"\n",
    "        \n",
    "        if i % 3 == 0:\n",
    "            Z_CAUCHY = X_N[:,i]+ X_N[:,i]*np.random.standard_cauchy(size=(X.shape[0]))\n",
    "            MUT[:,i] = Z_CAUCHY\n",
    "        elif i % 3 == 1:\n",
    "            NORM_MUT_DEV = ((BEST-X_N[:,i])/12)**2 + 1e-9\n",
    "            Z_NORM = np.random.normal(BEST,NORM_MUT_DEV,size=(X.shape[0]))\n",
    "            MUT[:,i] = Z_NORM\n",
    "        elif i % 3 == 2:\n",
    "            lmbda = 1\n",
    "            LEVY_DEV = (gamma(1+lmbda)*np.sin(np.pi*lmbda/2)/(gamma((1+lmbda)/2)*lmbda*2**((lmbda-1)/2)))**(1/lmbda)\n",
    "            LEVY_U = np.random.normal(0,LEVY_DEV,size=(X.shape[0]))\n",
    "            LEVY_V = np.random.normal(0,1,size=(X.shape[0]))\n",
    "            Z_LEVY = X_N[:,i]+ 0.01*LEVY_U/(LEVY_V**(1/lmbda))\n",
    "            MUT[:,i] = Z_LEVY\n",
    "\n",
    "    X = np.hstack([X_N,Y_N,Y_M,Y_K,Y_L,MUT])\n",
    "    \n",
    "    #drop duplicates (substitution and substitute with random)\n",
    "\n",
    "    NUM = X.shape[1]\n",
    "    \n",
    "    X = np.unique(X, axis=1)\n",
    "    \n",
    "    if NUM-X.shape[1]>0:\n",
    "        sample_size = NUM-X.shape[1]\n",
    "        RAND = [np.random.uniform(l,u,size=(1,101)) for l,u in bounds]\n",
    "        RAND = np.vstack(RAND)\n",
    "        X = np.hstack([X,RAND])\n",
    "    \n",
    "\n",
    "    L = np.array([smooth_objective(X[:,i]) for i in range(X.shape[1])])\n",
    "\n",
    "    shift = np.argsort(L)\n",
    "\n",
    "    L = L[shift]\n",
    "    X = X[:,shift]\n",
    "    X = X[:,:1000]\n",
    "\n",
    "    X = X[:,:X.shape[1] - X.shape[1]%2]\n",
    "\n",
    "    X_N = X[:,:X.shape[1]//2] \n",
    "    X_M = X[:,X.shape[1]//2:]\n",
    "\n",
    "    print('iteration', _, 'minimum loss',np.min(L))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33152165, -0.69076081])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sol = X[:,0]\n",
    "gen_sol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
